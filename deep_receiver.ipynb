{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-26T08:45:22.960927300Z",
     "start_time": "2023-12-26T08:45:22.918057200Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, k_size):\n",
    "        super().__init__()\n",
    "        self.add_module(\"bn\", nn.BatchNorm1d(in_ch))\n",
    "        self.add_module(\"act\", nn.ReLU())\n",
    "        self.add_module(\"conv\", nn.Conv1d(in_ch, out_ch, k_size, padding=k_size//2))\n",
    "    \n",
    "    def forward(self, X):\n",
    "        for blk in self._models:\n",
    "            X = blk(X)\n",
    "        return X\n",
    "    \n",
    "    \n",
    "class DenseBlock(nn.Module):\n",
    "    def __init__(self, in_ch, conv_num, ch_num):\n",
    "        super().__init__()\n",
    "        self._out_ch = in_ch + ch_num * conv_num\n",
    "        for i in torch.arange(conv_num):\n",
    "            self.add_module(f\"basic_blk{i}\", BasicBlock(in_ch, ch_num, 3))\n",
    "            in_ch += ch_num\n",
    "    \n",
    "    def forward(self, X):\n",
    "        for blk in self._modules:\n",
    "            Y = blk(X)\n",
    "            X = torch.cat([X, Y])\n",
    "        return X\n",
    "    \n",
    "    def out_ch(self):\n",
    "        return self._out_ch\n",
    "            \n",
    "            \n",
    "class TransBlock(nn.Module):\n",
    "    def __init__(self, in_ch, conv_k_num, conv_k_size, pool_k_size, pool_step):\n",
    "        super().__init__()\n",
    "        self.add_module(\"basic_blk\", BasicBlock(in_ch, conv_k_num, conv_k_size))\n",
    "        self.add_module(\"pool\", nn.MaxPool1d(pool_k_size, pool_step, padding=pool_k_size//2))\n",
    "        \n",
    "    def forward(self, X):\n",
    "        for blk in self._models:\n",
    "            X = blk(X)\n",
    "        return X\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class Conv_DenseNet_1D(nn.Module):\n",
    "\n",
    "    loss = F.cross_entropy\n",
    "    device = torch.device('cuda:0')\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 密连接部分\n",
    "        dense_part = nn.Sequential()\n",
    "        dense_part.add_module(\"conv1\", nn.Conv1d(2, 64, 3, 1, 1))\n",
    "        dense_part.add_module(\"trans_blk1\", TransBlock(64, 128, 3, 3, 2))\n",
    "        dense_part.add_module(\"dense_blk1\", DenseBlock(128, 2, 128))\n",
    "        dense_part.add_module(\"trans_blk2\", TransBlock(128 * 2 + 128, 64, 3, 3, 2))\n",
    "        dense_part.add_module(\"dense_blk2\", DenseBlock(64, 3, 64))\n",
    "        dense_part.add_module(\"trans_blk3\", TransBlock(64 * 3 + 64, 64, 3, 3, 2))\n",
    "        dense_part.add_module(\"dense_blk3\", DenseBlock(64, 4, 64))\n",
    "        dense_part.add_module(\"trans_blk4\", TransBlock(64 * 4 + 64, 64, 3, 3, 2))\n",
    "        dense_part.add_module(\"dense_blk4\", DenseBlock(64, 3, 64))\n",
    "        dense_part.add_module(\"conv2\", nn.Conv1d(64 * 3 + 64, 150, 3, 1, 1))\n",
    "        self.add_module(\"dense_part\", dense_part)\n",
    "        # 全局池化部分\n",
    "        pool_part = {\n",
    "            \"max_pool\": nn.AdaptiveMaxPool1d(1),\n",
    "            \"avg_pool\": nn.AdaptiveAvgPool1d(1),\n",
    "        }\n",
    "        self._pools = pool_part\n",
    "        self.add_module(\"global_pool_part\", nn.Sequential(pool_part))\n",
    "        # 全连接部分\n",
    "        self.add_module(\"lin_part\", nn.Linear(300, 32*2))\n",
    "    \n",
    "    def __call__(self, X):\n",
    "        return self.forward(X)\n",
    "\n",
    "    def forward(self, X):\n",
    "        models = self._modules\n",
    "        pool_part = models[\"global_pool_part\"]\n",
    "        Y = models[\"dense_part\"](X)\n",
    "        feature_vec = torch.cat([pool_part[0](Y), pool_part[1](Y)], dim=1)\n",
    "        y = models[\"lin_part\"](feature_vec)\n",
    "        return y.reshape([-1, 32, 2])\n",
    "    \n",
    "    def predict(self, X):\n",
    "        torch.no_grad()\n",
    "        self.eval()\n",
    "        Y_hat = self(X)\n",
    "        y_hat = torch.argmax(Y_hat, dim=len(Y_hat.shape)-1)\n",
    "        return y_hat"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T08:45:27.217739800Z",
     "start_time": "2023-12-26T08:45:27.146243800Z"
    }
   },
   "id": "28d2f2489c05dfb6"
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T03:32:04.655488700Z",
     "start_time": "2024-01-01T03:32:04.636603400Z"
    }
   },
   "id": "154197913b381500"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "'x^0 + x^2 + x^5 + x^6 + x^8 + x^9 + x^10 '"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from commpy import modulation\n",
    "import numpy as np\n",
    "from commpy import channelcoding\n",
    "\n",
    "arr = np.random.randint(0, 2, [12])\n",
    "QAM = modulation.QAMModem(16)\n",
    "sig = QAM.modulate(arr)\n",
    "gen74 = channelcoding.cyclic_code_genpoly(7, 4)[0]\n",
    "gen155 = channelcoding.cyclic_code_genpoly(15, 5)[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T02:19:59.862582Z",
     "start_time": "2024-01-04T02:19:59.818524600Z"
    }
   },
   "id": "cf27b57210949a70"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "class Marker:\n",
    "    def __init__(self):\n",
    "        self._fig = plt.figure()\n",
    "        self._ax = self._fig.subplots()\n",
    "        self._train = [1]\n",
    "        self._test = [1]\n",
    "\n",
    "\n",
    "    def update(self, ebr_train, ebr_test):\n",
    "        self._train.append(ebr_train)\n",
    "        self._test.append(ebr_test)\n",
    "        # 数据可视化\n",
    "        self._ax.cla()\n",
    "        plt.yscale('log')\n",
    "        self._ax.set_ylim((10e-8, 1))\n",
    "        epochs = torch.arange(len(self._train))\n",
    "        self._ax.plot(epochs, self._train, label='train_ebr', color='blue')\n",
    "        self._ax.plot(epochs, self._test, label='test_ebr', color='green')\n",
    "        self._ax.legend(loc=\"upper left\")\n",
    "        display.display(self._fig)\n",
    "        display.clear_output(wait=True)\n",
    "\n",
    "\n",
    "def split_data(data_set, split_rate, shuffle=True):\n",
    "    feature, label = data_set\n",
    "    data_num = len(feature)\n",
    "    index = torch.arange(data_num)\n",
    "    if shuffle:\n",
    "        random.shuffle(index)\n",
    "    split_gap = np.array(split_rate).cumsum()\n",
    "    split_point = (split_gap * data_num / split_gap[-1]).astype(int)\n",
    "    index_start = [0, *split_point[:-1]]\n",
    "    index_end = split_point\n",
    "    data_parts = []\n",
    "    for start, end in zip(index_start, index_end):\n",
    "        i = index[start:end]\n",
    "        data_parts.append((feature[i], label[i]))\n",
    "    return data_parts\n",
    "    \n",
    "\n",
    "def load_data(data_set, batch_size):\n",
    "    feature, label = data_set\n",
    "    data_num = len(feature)\n",
    "    for start in range(0, data_num, batch_size):\n",
    "        end = min(start+batch_size, data_num)\n",
    "        yield feature[start:end], label[start:end]\n",
    "\n",
    "\n",
    "def run_epoch(net, data_set, batch_size, optimizer=None):\n",
    "    err_bits = 0\n",
    "    is_train = optimizer is not None\n",
    "    for X, y in load_data(data_set, batch_size, is_train):\n",
    "        X = X.to(net.device)\n",
    "        y = y.to(net.device)\n",
    "        if is_train:\n",
    "            optimizer.zero_grad()\n",
    "            Y_hat = net(X)\n",
    "            loss = net.loss(Y_hat, y)\n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                optimizer.step()\n",
    "                y_hat = torch.argmax(Y_hat, dim=len(Y_hat.shape)-1)\n",
    "        else:\n",
    "            y_hat = net.predict(X)\n",
    "        err_bits += torch.sum(~(y_hat == y))        \n",
    "    return err_bits.cpu() / len(data_set)\n",
    "\n",
    "\n",
    "def train(net, data_set, batch_size, lr, lr_gain, epochs, steady_epochs, momentum):\n",
    "    steady_epoch = 0\n",
    "    marker = Marker()\n",
    "    for epoch in range(epochs):\n",
    "        train_set, valid_set = split_data(data_set, [8, 2])\n",
    "        if steady_epoch >= steady_epochs:\n",
    "            lr *= lr_gain\n",
    "            steady_epoch = 0\n",
    "        optimizer = torch.optim.SGD(net.parameters(), lr, momentum)\n",
    "        # 训练和验证\n",
    "        ebr_train = run_epoch(net, train_set, batch_size, optimizer)\n",
    "        ebr_valid = run_epoch(net, valid_set, batch_size)\n",
    "        # 更新图像\n",
    "        marker.update(ebr_train, ebr_valid)\n",
    "        # 记一次lr稳定的epoch\n",
    "        steady_epoch += 1\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T08:34:01.806826100Z",
     "start_time": "2023-12-26T08:34:01.751728Z"
    }
   },
   "id": "ef2d14b21939f642"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[24, 25, 26, 27],\n         [28, 29, 30, 31],\n         [32, 33, 34, 35]],\n\n        [[36, 37, 38, 39],\n         [40, 41, 42, 43],\n         [44, 45, 46, 47]]])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.arange(12*3*4).reshape([12,3,4]).split(2, dim=0)[1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T02:01:48.440819Z",
     "start_time": "2023-12-30T02:01:48.406862300Z"
    }
   },
   "id": "16d9f654880d24d2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
