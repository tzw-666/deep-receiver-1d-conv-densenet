{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[<__main__.NoiseTrainSet at 0x2369b9752a0>,\n <__main__.NoiseTrainSet at 0x2369b976fe0>,\n <__main__.NoiseTrainSet at 0x2369b975a50>,\n <__main__.NoiseTrainSet at 0x2369b976f80>]"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from communication_system import *\n",
    "from deep_receiver import *\n",
    "import pickle\n",
    "\n",
    "retrain = False\n",
    "\n",
    "# test1：AWGN channel\n",
    "# generate training set \n",
    "train_set_sample_num =  2 * 1000 * 9\n",
    "data_bits = gen_rand_code(32, train_set_sample_num)\n",
    "\n",
    "moder = {\n",
    "    \"bpsk\": PSKModem(2),\n",
    "    \"qpsk\": PSKModem(4)\n",
    "}\n",
    "\n",
    "\n",
    "class DeepSet:\n",
    "    def __init__(self, mod_name , noise):\n",
    "        self.mod = moder[mod_name]\n",
    "        self.mod_name = mod_name\n",
    "        self.noise = noise\n",
    "        self.net = Conv_DenseNet_1D()\n",
    "        self.train_ebr_log = None\n",
    "        self.test_ebr = None\n",
    "\n",
    "var_file = \"data\\\\additional_noise_deep_set.data\"\n",
    "\n",
    "deep_set = None\n",
    "\n",
    "if not os.path.exists(var_file) or retrain:\n",
    "    print(\"need to train nets\")\n",
    "    deep_set = [\n",
    "        DeepSet(\"bpsk\", 'awgn'),\n",
    "        DeepSet(\"qpsk\",'awgn'),\n",
    "        DeepSet(\"bpsk\", 'aggn'),\n",
    "        DeepSet(\"qpsk\", 'aggn')\n",
    "    ]\n",
    "    \n",
    "    ham74 = Hamming74()\n",
    "    coded_data_bits = ham74.encode(data_bits)\n",
    "    EbN0 = np.arange(9)\n",
    "    for setting in deep_set:\n",
    "        mod_data, _, _ = modulate(coded_data_bits, setting.mod, True)\n",
    "        \n",
    "        # generate noise\n",
    "        SNR = EbN02SNR(EbN0, setting.mod.num_bits_symbol, 8)\n",
    "        \n",
    "        # generate training set\n",
    "        noised_data = []\n",
    "        for mod_data_part, snr in zip(mod_data.reshape([9, len(mod_data)//9, -1]), SNR):\n",
    "            noised_data.append(add_noise(mod_data_part, setting.noise, snr))\n",
    "        noised_data = np.concatenate(noised_data, 0)\n",
    "        train_set = (torch.tensor(noised_data), torch.tensor(data_bits))\n",
    "        \n",
    "        # 训练模型\n",
    "        print(f\"net(modulate:{setting.mod}, noise:{setting.noise}) start training\")\n",
    "        setting.train_ebr_log = train(\n",
    "            net = setting.net,\n",
    "            data_set = train_set,\n",
    "            batch_size = 256,\n",
    "            lr = 0.001,\n",
    "            lr_gain = 0.1,\n",
    "            epochs = 8,\n",
    "            steady_epochs = 2,\n",
    "            momentum = 0.9\n",
    "        )\n",
    "        print(f\"net(modulate:{setting.mod}, noise:{setting.noise}) training done\")\n",
    "        \n",
    "    # 存储模型变量\n",
    "    print(f\"save the data to the file:{var_file}\")\n",
    "    fp = open(var_file, \"wb\")\n",
    "    pickle.dump(deep_set, fp)\n",
    "    fp.close()\n",
    "else:\n",
    "    print(f\"load the data from the file:{var_file}\")\n",
    "    fp = open(var_file, \"rb\")\n",
    "    deep_set = pickle.load(fp)\n",
    "    fp.close()\n",
    "   \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T01:21:02.947096Z",
     "start_time": "2024-03-18T01:20:49.420629Z"
    }
   },
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "Test_Model_V_fangan67_lite.cpp"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "commpy.modulation.PSKModem"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T02:27:04.290558Z",
     "start_time": "2024-03-18T02:27:04.281379Z"
    }
   },
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# \n",
    "delta_f = np.random.uniform(-0.01, 0.01, 1000)\n",
    "signal_f_off_data = [add_frequency_offset(signal, 8, 0.01) for signal in signal_data]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T07:53:23.127287Z",
     "start_time": "2024-03-11T07:53:23.088373Z"
    }
   },
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# IQ imbalance\n",
    "for i, j in zip(np.arange(12), np.repeat(np.arange(12).reshape([-1, 1]), 3, 1)):\n",
    "    print(i, j)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
